#!/usr/bin/env python3
"""
–í—ã–±–æ—Ä–∫–∞ –ª–µ–º–º –∏–∑ Lexique383:
- VER, NOM, ADJ, ADV: —Ç–æ–ø-10000 –ø–æ —Å—É–º–º–µ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–µ–π
- –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: –≤—Å–µ –ª–µ–º–º—ã
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ñ–∞–π–ª–∞–º: –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚â•100 —Å–ª–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤ other.csv
"""

import pandas as pd
from pathlib import Path

LEXIQUE_PATH = Path("Lexique383.tsv")
OUTPUT_DIR = Path("categories")

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏
FREQ_FILTERED_CATEGORIES = ['VER', 'NOM', 'ADJ', 'ADV']
TOP_N = 10000

# –ü–æ—Ä–æ–≥ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
MIN_CATEGORY_SIZE = 100

# –í—ã—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
OUTPUT_COLS = ['lemme', 'cgram', 'genre', 'freqlem', 'forms', 'nbhomogr']


def get_word_forms(df: pd.DataFrame) -> dict[tuple[str, str], str]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —Ñ–æ—Ä–º—ã —Å–ª–æ–≤ –ø–æ —Ä–æ–¥—É –∏ —á–∏—Å–ª—É –¥–ª—è –∫–∞–∂–¥–æ–π –ª–µ–º–º—ã+cgram.

    Returns:
        dict[(lemme, cgram)] -> "—Ñ–æ—Ä–º–∞1/—Ñ–æ—Ä–º–∞2 —Ñ–æ—Ä–º–∞3/—Ñ–æ—Ä–º–∞4"
    """
    forms_dict = {}

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ª–µ–º–º–µ –∏ –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    for (lemme, cgram), group in df.groupby(['lemme', 'cgram']):
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ—Ä–º—ã –ø–æ —Ä–æ–¥—É –∏ —á–∏—Å–ª—É
        forms_by_gn = {}  # (genre, nombre) -> set(ortho)

        for _, row in group.iterrows():
            genre = row['genre'] if pd.notna(row['genre']) else ''
            nombre = row['nombre'] if pd.notna(row['nombre']) else ''
            ortho = row['ortho']

            key = (genre, nombre)
            if key not in forms_by_gn:
                forms_by_gn[key] = set()
            forms_by_gn[key].add(ortho)

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Ñ–æ—Ä–º
        forms_str = _format_forms(lemme, forms_by_gn)
        forms_dict[(lemme, cgram)] = forms_str

    return forms_dict


def _format_forms(lemme: str, forms_by_gn: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º—ã —Å–ª–æ–≤–∞ –≤ —Å—Ç—Ä–æ–∫—É.

    –§–æ—Ä–º–∞—Ç—ã:
    - –û–¥–Ω–∞ —Ñ–æ—Ä–º–∞: lemme
    - –î–≤–µ —Ñ–æ—Ä–º—ã (–µ–¥./–º–Ω.): –µ–¥, –º–Ω
    - –ß–µ—Ç—ã—Ä–µ —Ñ–æ—Ä–º—ã (–º/–∂ √ó –µ–¥/–º–Ω): –º.–µ–¥/–∂.–µ–¥ –º.–º–Ω/–∂.–º–Ω
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–æ—Ä–º—ã –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
    ms = forms_by_gn.get(('m', 's'), forms_by_gn.get(('', 's'), set()))
    fs = forms_by_gn.get(('f', 's'), set())
    mp = forms_by_gn.get(('m', 'p'), forms_by_gn.get(('', 'p'), set()))
    fp = forms_by_gn.get(('f', 'p'), set())

    # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —á–∏—Å–ª–µ, –±–µ—Ä—ë–º —Ñ–æ—Ä–º—ã –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è —á–∏—Å–ª–∞
    if not ms and not mp:
        ms = forms_by_gn.get(('m', ''), forms_by_gn.get(('', ''), set()))
    if not fs and not fp:
        fs = forms_by_gn.get(('f', ''), set())

    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é —Ñ–æ—Ä–º—É –∏–∑ –∫–∞–∂–¥–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞
    def first(s):
        return next(iter(s)) if s else ''

    ms_form = first(ms)
    fs_form = first(fs)
    mp_form = first(mp)
    fp_form = first(fp)

    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—ã
    all_forms = {f for f in [ms_form, fs_form, mp_form, fp_form] if f}

    if len(all_forms) == 0:
        return lemme

    if len(all_forms) == 1:
        return first(all_forms)

    # –ï—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏—è –ø–æ —Ä–æ–¥—É?
    has_gender_diff = fs_form and ms_form and fs_form != ms_form
    # –ï—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏—è –ø–æ —á–∏—Å–ª—É?
    has_number_diff = (mp_form and ms_form and mp_form != ms_form) or \
                      (fp_form and fs_form and fp_form != fs_form)

    if has_gender_diff and has_number_diff:
        # –ß–µ—Ç—ã—Ä–µ —Ñ–æ—Ä–º—ã: –º.–µ–¥/–∂.–µ–¥ –º.–º–Ω/–∂.–º–Ω
        sg = f"{ms_form}/{fs_form}" if ms_form and fs_form else (ms_form or fs_form)
        pl = f"{mp_form}/{fp_form}" if mp_form and fp_form else (mp_form or fp_form)
        if pl:
            return f"{sg} {pl}"
        return sg
    elif has_gender_diff:
        # –î–≤–µ —Ñ–æ—Ä–º—ã –ø–æ —Ä–æ–¥—É: –º/–∂
        return f"{ms_form}/{fs_form}"
    elif has_number_diff:
        # –î–≤–µ —Ñ–æ—Ä–º—ã –ø–æ —á–∏—Å–ª—É: –µ–¥, –º–Ω
        sg = ms_form or fs_form
        pl = mp_form or fp_form
        return f"{sg}, {pl}"
    else:
        # –û–¥–Ω–∞ —Ñ–æ—Ä–º–∞
        return first(all_forms)


def main():
    if not LEXIQUE_PATH.exists():
        print(f"‚ùå –§–∞–π–ª {LEXIQUE_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("   –°–∫–∞—á–∞–π —Å: http://www.lexique.org/databases/Lexique383/Lexique383.tsv")
        return

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    OUTPUT_DIR.mkdir(exist_ok=True)

    # –ó–∞–≥—Ä—É–∑–∫–∞
    df = pd.read_csv(LEXIQUE_PATH, sep='\t', low_memory=False)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∏–∑ Lexique383")

    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ—Ä–º—ã —Å–ª–æ–≤ (–¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ islem)
    print("üìù –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ—Ä–º—ã —Å–ª–æ–≤...")
    forms_dict = get_word_forms(df)
    print(f"   –°–æ–±—Ä–∞–Ω–æ —Ñ–æ—Ä–º –¥–ª—è {len(forms_dict):,} –ª–µ–º–º")

    # 1. –¢–æ–ª—å–∫–æ –ª–µ–º–º—ã
    lemmas = df[df['islem'] == 1].copy()
    print(f"üìã –õ–µ–º–º (islem=1): {len(lemmas):,}")

    # 2. –í—ã—á–∏—Å–ª—è–µ–º freqlem
    lemmas['freqlem'] = (
        lemmas['freqlemfilms2'].fillna(0) +
        lemmas['freqlemlivres'].fillna(0)
    )

    # 3. –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º—ã
    lemmas['forms'] = lemmas.apply(
        lambda row: forms_dict.get((row['lemme'], row['cgram']), row['lemme']),
        axis=1
    )

    # 4. –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –¥–≤–µ –≥—Ä—É–ø–ø—ã
    freq_filtered = lemmas[lemmas['cgram'].isin(FREQ_FILTERED_CATEGORIES)].copy()
    other = lemmas[~lemmas['cgram'].isin(FREQ_FILTERED_CATEGORIES)].copy()

    print(f"\nüìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º ({', '.join(FREQ_FILTERED_CATEGORIES)}):")
    print(f"   –í—Å–µ–≥–æ: {len(freq_filtered):,}")

    # 5. –î–ª—è VER/NOM/ADJ/ADV: —Ç–æ–ø-10000 –ø–æ freqlem
    freq_filtered = freq_filtered.nlargest(TOP_N, 'freqlem')
    print(f"‚úÇÔ∏è  –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ —Ç–æ–ø-{TOP_N:,}: {len(freq_filtered):,}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ —Ç–æ–ø–µ
    print(f"\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Ç–æ–ø-{TOP_N:,}:")
    for cat in FREQ_FILTERED_CATEGORIES:
        count = len(freq_filtered[freq_filtered['cgram'] == cat])
        print(f"   {cat:<6} {count:>6}")

    # 6. –û–±—ä–µ–¥–∏–Ω—è–µ–º (–∏—Å–∫–ª—é—á–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    other = other[other['cgram'].notna()]
    result = pd.concat([freq_filtered, other], ignore_index=True)

    # 7. –û—Å—Ç–∞–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    result = result[OUTPUT_COLS].copy()

    # 8. –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_counts = result['cgram'].value_counts()

    large_categories = category_counts[category_counts >= MIN_CATEGORY_SIZE].index.tolist()
    small_categories = category_counts[category_counts < MIN_CATEGORY_SIZE].index.tolist()

    print(f"\nüìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (‚â•{MIN_CATEGORY_SIZE}):")
    for cat in sorted(large_categories):
        print(f"   {cat:<12} {category_counts[cat]:>6}")

    print(f"\nüìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è other.csv (<{MIN_CATEGORY_SIZE}):")
    for cat in sorted(small_categories):
        print(f"   {cat:<12} {category_counts[cat]:>6}")

    # 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã
    total_saved = 0

    for cat in large_categories:
        cat_data = result[result['cgram'] == cat].copy()
        cat_data = cat_data.sort_values('freqlem', ascending=False)

        # –ò–º—è —Ñ–∞–π–ª–∞: –∑–∞–º–µ–Ω—è–µ–º : –Ω–∞ _
        filename = cat.replace(':', '_') + '.csv'
        filepath = OUTPUT_DIR / filename
        cat_data.to_csv(filepath, index=False)

        print(f"   üíæ {filename}: {len(cat_data):,} –ª–µ–º–º")
        total_saved += len(cat_data)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º other.csv
    other_data = result[result['cgram'].isin(small_categories)].copy()
    other_data = other_data.sort_values(['cgram', 'freqlem'], ascending=[True, False])
    other_path = OUTPUT_DIR / 'other.csv'
    other_data.to_csv(other_path, index=False)

    print(f"   üíæ other.csv: {len(other_data):,} –ª–µ–º–º")
    total_saved += len(other_data)

    print(f"\n" + "=" * 60)
    print(f"‚úÖ –ò–¢–û–ì–û: {total_saved:,} –ª–µ–º–º")
    print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {OUTPUT_DIR}/")
    print("=" * 60)

    # –ü—Ä–µ–≤—å—é
    print(f"\nüìù –ü—Ä–µ–≤—å—é ADJ (–ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫):")
    adj_preview = result[result['cgram'] == 'ADJ'].nlargest(5, 'freqlem')
    print(adj_preview.to_string(index=False))


if __name__ == "__main__":
    main()
